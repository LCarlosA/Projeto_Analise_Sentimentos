{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X22v9hfaAXx_"
      },
      "source": [
        "## Etapa 1: Importação de bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Via8z9VMSFZJ"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQpZkUrnATO0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import seaborn as sns\n",
        "import spacy as sp\n",
        "import string\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk import tokenize\n",
        "import nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-hghf4QhMDv"
      },
      "outputs": [],
      "source": [
        "nltk.download('rslp') #Utilizado na stemmização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNo4LiuDPtbj"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkF2vekvLDZG"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZPogBZDAUyH"
      },
      "outputs": [],
      "source": [
        "# ATUALIZAÇÃO AGO-2024\n",
        "# %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scR0laZDAfla"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHgRt2ufAjI2"
      },
      "source": [
        "# Dados de Treino:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH1Iv8NdYnqE"
      },
      "source": [
        "## Etapa 2: Pré-Processamento de dados: Limpeza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loCo9fOkA_Ai"
      },
      "outputs": [],
      "source": [
        "cols = ['text','label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PP5meMZHBM2s"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('emotions_pt.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hA7Fh05sBYan"
      },
      "outputs": [],
      "source": [
        "train_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Q6I-qSICAet"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMv5vF_JCD-j"
      },
      "outputs": [],
      "source": [
        "train_data['label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjInEfOJCGlc"
      },
      "outputs": [],
      "source": [
        "sns.countplot( x = train_data['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17L4wdHEr9b6"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.drop(train_data[train_data['label'] == 1].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVbUKrCNCLo9"
      },
      "outputs": [],
      "source": [
        "train_data.replace(2,1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YT8dFBLDK_f"
      },
      "outputs": [],
      "source": [
        "sns.countplot( x = train_data['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMKVGFJFLHEt"
      },
      "outputs": [],
      "source": [
        "data = train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_I5E4yiLG4J"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iZUCiiaRRLr"
      },
      "outputs": [],
      "source": [
        "X = data.iloc[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbDHdLhLRRJP"
      },
      "outputs": [],
      "source": [
        "y = data.iloc[:, 1]\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h0RX_2XRRGe"
      },
      "outputs": [],
      "source": [
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVBzBLYjm03t"
      },
      "outputs": [],
      "source": [
        "data_labels = y\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWCc6m7krmO-"
      },
      "source": [
        "Inutil?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TOD8QVIRRD0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X, _, y, _ = train_test_split(X, y, test_size = 0.85, stratify = y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyFp-IBpYy5p"
      },
      "source": [
        "## Tratativa de linguagem:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptxNtX6XfRiJ"
      },
      "outputs": [],
      "source": [
        "todas_palavras = ' '.join([texto for texto in data['text']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkUqEkvDfCzj"
      },
      "outputs": [],
      "source": [
        "token_espaco = tokenize.WhitespaceTokenizer()\n",
        "\n",
        "token_frase = token_espaco.tokenize(todas_palavras)\n",
        "frequencia = nltk.FreqDist(token_frase)\n",
        "frequencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVuNrY32fy9e"
      },
      "outputs": [],
      "source": [
        "def pareto(texto, coluna_texto, quantidade):\n",
        "    todas_palavras = ' '.join([texto for texto in texto[coluna_texto]])\n",
        "    token_frase = token_espaco.tokenize(todas_palavras)\n",
        "    frequencia = nltk.FreqDist(token_frase)\n",
        "    df_frequencia = pd.DataFrame({\"Palavra\": list(frequencia.keys()),\n",
        "                                   \"Frequência\": list(frequencia.values())})\n",
        "    df_frequencia = df_frequencia.nlargest(columns = \"Frequência\", n = quantidade)\n",
        "    plt.figure(figsize=(12,8))\n",
        "    ax = sns.barplot(data = df_frequencia, x = \"Palavra\", y = \"Frequência\", color = 'gray')\n",
        "    ax.set(ylabel = \"Contagem\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSbXmSaGpxyD"
      },
      "outputs": [],
      "source": [
        "def word_cloud(text, column_text):\n",
        "      all_words = ' '.join([text for text in text[column_text]])\n",
        "\n",
        "      word_cloud = WordCloud(width = 800, height = 400,\n",
        "                              max_font_size = 110, collocations = False).generate(all_words)\n",
        "\n",
        "      plt.figure(figsize = (10,7))\n",
        "      plt.imshow(word_cloud, interpolation = 'bilinear')\n",
        "      plt.axis('off')\n",
        "      plt.title('Nuvem de palavras:')\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnAoI0lkqjl3"
      },
      "outputs": [],
      "source": [
        "word_cloud(data, 'text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoIXNpfhgOFF"
      },
      "outputs": [],
      "source": [
        "pareto(data,'text',10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AuqkIK_pQez"
      },
      "outputs": [],
      "source": [
        "def clean_tweets(tweet):\n",
        "  tweet = BeautifulSoup(tweet, 'lxml').get_text()\n",
        "  tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
        "  tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
        "  tweet = re.sub(r\"[^a-zA-Z.!?]\", ' ', tweet)\n",
        "  tweet = re.sub(r\" +\", ' ', tweet)\n",
        "  return tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5-F4262tgTj"
      },
      "outputs": [],
      "source": [
        "data['tratamento1'] = data['text'].apply(clean_tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5RcI8-atowB"
      },
      "outputs": [],
      "source": [
        "word_cloud(data, 'tratamento1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4cpPM52gXZm"
      },
      "outputs": [],
      "source": [
        "pareto(data, \"tratamento1\", 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOVkdDBupQcW"
      },
      "outputs": [],
      "source": [
        "nlp = sp.load('pt_core_news_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yvgg9Ir8pQZi"
      },
      "outputs": [],
      "source": [
        "stop_words = sp.lang.pt.STOP_WORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvhT2hr7pQXE"
      },
      "outputs": [],
      "source": [
        "string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrpoBd_6pQUv"
      },
      "outputs": [],
      "source": [
        "def clean_tweets2(tweet):\n",
        "\n",
        "    tweet = tweet.lower()\n",
        "    document = nlp(tweet)\n",
        "\n",
        "    words = []\n",
        "\n",
        "    for token in document:\n",
        "        if token.text not in stop_words and token.text not in string.punctuation:\n",
        "            words.append(token.text)\n",
        "\n",
        "    # Juntar as palavras em uma string final\n",
        "    cleaned_tweet = ' '.join(words)\n",
        "\n",
        "    return cleaned_tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ux_EAuGU19PX"
      },
      "outputs": [],
      "source": [
        "text = 'hoje eu testei meus dados!'\n",
        "clean_tweets2(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SovI2VPxpQSG"
      },
      "outputs": [],
      "source": [
        "data['tratamento2'] = data['tratamento1'].apply(clean_tweets2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSz7LfTBX2T-"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWM5eKbFdvLY"
      },
      "outputs": [],
      "source": [
        "word_cloud(data, 'tratamento2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozvNAmRmgyl_"
      },
      "outputs": [],
      "source": [
        "pareto(data, \"tratamento2\", 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0Adh9qKenzC"
      },
      "outputs": [],
      "source": [
        "stemmer = nltk.RSLPStemmer()\n",
        "\n",
        "\n",
        "frase_processada = list()\n",
        "for opiniao in data['tratamento2']:\n",
        "    nova_frase = list()\n",
        "    palavras_texto = token_espaco.tokenize(opiniao)\n",
        "    for palavra in palavras_texto:\n",
        "        nova_frase.append(stemmer.stem(palavra))\n",
        "    frase_processada.append(' '.join(nova_frase))\n",
        "data['tratamento3'] = frase_processada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FA0wF5yShtqU"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgvyohu5h7yL"
      },
      "outputs": [],
      "source": [
        "word_cloud(data, 'tratamento3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9A62Fbhth9eq"
      },
      "outputs": [],
      "source": [
        "pareto(data, \"tratamento3\", 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuM2RKJOh9KP"
      },
      "outputs": [],
      "source": [
        "data.drop(['text','tratamento1','tratamento2'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn9A6Uq9mpF8"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRELvV2wVyKC"
      },
      "outputs": [],
      "source": [
        "data_clean = data['tratamento3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPZR-6bpY95f"
      },
      "source": [
        "## Tokenização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D7V24O5aBjm"
      },
      "outputs": [],
      "source": [
        "2**16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr3IOgheLGn2"
      },
      "outputs": [],
      "source": [
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(data_clean, target_vocab_size = 2**16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNyGiZoFa_si"
      },
      "outputs": [],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fV44aBfLa_R9"
      },
      "outputs": [],
      "source": [
        "ids = tokenizer.encode('eu sou feliz')\n",
        "print(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq_WhMbda_Pj"
      },
      "outputs": [],
      "source": [
        "text = tokenizer.decode(ids)\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVEHElp8a_NJ"
      },
      "outputs": [],
      "source": [
        "data_inputs = [tokenizer.encode(sentence) for sentence in data_clean]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZ-VHpWna_Kp"
      },
      "outputs": [],
      "source": [
        "for _ in range(10):\n",
        "  print(data_inputs[random.randint(0, len(data_inputs) -1 )])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfynsCwvclNe"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XshbEqZLecSj"
      },
      "outputs": [],
      "source": [
        "max_len = max([len(sentence) for sentence in data_inputs])\n",
        "max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e2JZA7JecQM"
      },
      "outputs": [],
      "source": [
        "data_inputs = tf.keras.preprocessing.sequence.pad_sequences(data_inputs,\n",
        "                                                            value = 0,\n",
        "                                                            padding = 'post',\n",
        "                                                            maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BBoiT7becNg"
      },
      "outputs": [],
      "source": [
        "for _ in range(10):\n",
        "  print(data_inputs[random.randint(0, len(data_inputs) - 1)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh1gaHn9fSdN"
      },
      "source": [
        "### Divisão entre treino e teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZewYCtc4f03X"
      },
      "outputs": [],
      "source": [
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(data_inputs,\n",
        "                                                                        data_labels,\n",
        "                                                                        test_size = 0.3,\n",
        "                                                                        stratify = data_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvcRIuyvf009"
      },
      "outputs": [],
      "source": [
        "test_labels.to_csv('test_labels.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4G2SJOw-GhN"
      },
      "outputs": [],
      "source": [
        "train_labels.to_csv('train_labels.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OBX9q9D-Gdt"
      },
      "outputs": [],
      "source": [
        "np.savetxt('train_inputs.csv', train_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1Tb_xuM-GaM"
      },
      "outputs": [],
      "source": [
        "np.savetxt('test_inputs.csv', test_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BYyr7j_OzUb"
      },
      "outputs": [],
      "source": [
        "data.to_csv('data.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jx6sNdIJRUDA"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddVF0jSoYmyi"
      },
      "outputs": [],
      "source": [
        "train_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJxv07bHYmvC"
      },
      "outputs": [],
      "source": [
        "test_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APzPrTEhYmsr"
      },
      "outputs": [],
      "source": [
        "train_inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQukoU2ZYmqW"
      },
      "outputs": [],
      "source": [
        "test_inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URrP_koiYmoF"
      },
      "outputs": [],
      "source": [
        "len(set(train_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSX8lU6TInv2"
      },
      "source": [
        "## Etapa 2: Pré-Processamento de dados - Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itt0t4X4Ilp4"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv('BaseTweets.csv')\n",
        "test_data.drop_duplicates(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL1ggr0aJLdv"
      },
      "outputs": [],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFVapBY6KBXt"
      },
      "outputs": [],
      "source": [
        "test_data.rename(columns = {'text':'resenha'}, inplace = True)\n",
        "test_data.rename(columns = {'createdAt':'datapublicacao'}, inplace = True)\n",
        "test_data.rename(columns = {'retweetatCount':'retweets'}, inplace = True)\n",
        "test_data.rename(columns = {'viewCount':'views'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPazhrLeL0X6"
      },
      "outputs": [],
      "source": [
        "test_data['views'].fillna(test_data['views'].mean(), inplace = True)\n",
        "test_data['views'] = test_data['views'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxLz1F5JMhmx"
      },
      "outputs": [],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9udF3we9M8fi"
      },
      "outputs": [],
      "source": [
        "  test_data['datapublicacao'] = pd.to_datetime(test_data['datapublicacao'], format = '%a %b %d %H:%M:%S %z %Y')\n",
        "  test_data = test_data.sort_values('datapublicacao')\n",
        "  test_data['datapublicacao'] = test_data['datapublicacao'].dt.strftime('%d/%m/%Y')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vjjVdORNpvP"
      },
      "outputs": [],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE9ystoRIOK0"
      },
      "outputs": [],
      "source": [
        "data_clean = [clean_tweets2(clean_tweets(tweet)) for tweet in X]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5ZD5M3WKISC"
      },
      "outputs": [],
      "source": [
        "for _ in range(10):\n",
        "  print(data_clean[random.randint(0, len(data_clean) - 1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hYA7kfSKpP5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}